
ID: h8k1jur8,
Text: does non covid lung lesion help investigating transferability in covid ct image segmentation coronavirus disease covid is a highly contagious virus spreading all around the world deep learning has been adopted as an effective technique to aid covid detection and segmentation from computed tomography ct images the major challenge lies in the inadequate public covid datasets recently transfer learning has become a widely used technique that leverages the knowledge gained while solving one problem and applying it to a different but related problem however it remains unclear whether various non covid lung lesions could contribute to segmenting covid infection areas and how to better conduct this transfer procedure this paper provides a way to understand the transferability of non covid lung lesions based on a publicly available covid ct dataset and three public non covid datasets we evaluate four transfer learning methods using d u net as a standard encoder decoder method the results reveal the benefits of transferring knowledge from non covid lung lesions and learning from multiple lung lesion datasets can extract more general features leading to accurate and robust pre trained models we further show the capability of the encoder to learn feature representations of lung lesions which improves segmentation accuracy and facilitates training convergence in addition our proposed multi encoder learning method incorporates transferred lung lesion features from non covid datasets effectively and achieves significant improvement these findings promote new insights into transfer learning for covid ct image segmentation which can also be further generalized to other medical tasks

ID: r0j0368k,
Text: covid mobility data collection of seoul south korea the relationship between pandemic and human mobility has received considerable attention from scholars as investigating such relationship can provide an indication of how human mobility changes in response to a public health crisis or whether reduced mobility contributes to preventing the spread of an infectious disease while several studies attempted to unveil this relationship no studies have focused on changes in mobility pattern at a finer scale utilizing high resolution datasets to address the complex association between pandemic s spread and human mobility this paper presents two categories of mobility datasets trip mode and trip purpose that concern nearly million citizens movements during the first days of covid in seoul south korea where no major lockdown has been imposed we curate hourly data of subway ridership traffic volume and population present count at selected points of interests the results to be derived from the presented datasets can be used as an important reference for public health decision making in the post covid era

ID: vsl94lhz,
Text: twitter sentiment classification for measuring public health concerns an important task of public health officials is to keep track of health issues such as spreading epidemics in this paper we are addressing the issue of spreading public concern about epidemics public concern about a communicable disease can be seen as a problem of its own keeping track of trends in concern about public health and identifying peaks of public concern are therefore crucial tasks however monitoring public health concerns is not only expensive with traditional surveillance systems but also suffers from limited coverage and significant delays to address these problems we are using twitter messages which are available free of cost are generated world wide and are posted in real time we are measuring public concern using a two step sentiment classification approach in the first step we distinguish personal tweets from news i e non personal tweets in the second step we further separate personal negative from personal non negative tweets both these steps consist themselves of two sub steps in the first sub step of both steps our programs automatically generate training data using an emotion oriented clue based method in the second sub step we are training and testing three different machine learning ml models with the training data from the first sub step this allows us to determine the best ml model for different datasets furthermore we are testing the already trained ml models with a human annotated disjoint dataset based on the number of tweets classified as personal negative we compute a measure of concern moc and a timeline of the moc we attempt to correlate peaks of the moc timeline to peaks of the news non personal timeline our best accuracy results are achieved using the two step method with a naïve bayes classifier for the epidemic domain six datasets and the mental health domain three datasets

ID: yoav2b35,
Text: policycloud analytics as a service facilitating efficient data driven public policy management while several application domains are exploiting the added value of analytics over various datasets to obtain actionable insights and drive decision making the public policy management domain has not yet taken advantage of the full potential of the aforementioned analytics and data models diverse and heterogeneous datasets are being generated from various sources which could be utilized across the complete policies lifecycle i e modelling creation evaluation and optimization to realize efficient policy management to this end in this paper we present an overall architecture of a cloud based environment that facilitates data retrieval and analytics as well as policy modelling creation and optimization the environment enables data collection from heterogeneous sources linking and aggregation complemented with data cleaning and interoperability techniques in order to make the data ready for use an innovative approach for analytics as a service is introduced and linked with a policy development toolkit which is an integrated web based environment to fulfil the requirements of the public policy ecosystem stakeholders

ID: 5ll60v8p,
Text: statistical explorations and univariate timeseries analysis on covid datasets to understand the trend of disease spreading and death severe acute respiratory syndrome coronavirus sars cov the novel coronavirus is responsible for the ongoing worldwide pandemic world health organization who assigned an international classification of diseases icd code covid as the name of the new disease coronaviruses are generally transferred by people and many diverse species of animals including birds and mammals such as cattle camels cats and bats infrequently the coronavirus can be transferred from animals to humans and then propagate among people such as with middle east respiratory syndrome mers cov severe acute respiratory syndrome sars cov and now with this new virus namely sars cov or human coronavirus its rapid spreading has sent billions of people into lockdown as health services struggle to cope up the covid outbreak comes along with an exponential growth of new infections as well as a growing death count a major goal to limit the further exponential spreading is to slow down the transmission rate which is denoted by a spread factor f and we proposed an algorithm in this study for analyzing the same this paper addresses the potential of data science to assess the risk factors correlated with covid after analyzing existing datasets available in ourworldindata org oxford university database and newly simulated datasets following the analysis of different univariate long short term memory lstm models for forecasting new cases and resulting deaths the result shows that vanilla stacked and bidirectional lstm models outperformed multilayer lstm models besides we discuss the findings related to the statistical analysis on simulated datasets for correlation analysis we included features such as external temperature rainfall sunshine population infected cases death country population area and population density of the past three months january february and march in for univariate timeseries forecasting using lstm we used datasets from january to april

ID: 30ri8v61,
Text: statistical explorations and univariate timeseries analysis on covid datasets to understand the trend of disease spreading and death severe acute respiratory syndrome coronavirus sars cov the novel coronavirus is responsible for the ongoing worldwide pandemic world health organization who assigned an international classification of diseases icd code covid as the name of the new disease coronaviruses are generally transferred by people and many diverse species of animals including birds and mammals such as cattle camels cats and bats infrequently the coronavirus can be transferred from animals to humans and then propagate among people such as with middle east respiratory syndrome mers cov severe acute respiratory syndrome sars cov and now with this new virus namely sars cov or human coronavirus its rapid spreading has sent billions of people into lockdown as health services struggle to cope up the covid outbreak comes along with an exponential growth of new infections as well as a growing death count a major goal to limit the further exponential spreading is to slow down the transmission rate which is denoted by a spread factor f and we proposed an algorithm in this study for analyzing the same this paper addresses the potential of data science to assess the risk factors correlated with covid after analyzing existing datasets available in ourworldindata org oxford university database and newly simulated datasets following the analysis of different univariate long short term memory lstm models for forecasting new cases and resulting deaths the result shows that vanilla stacked and bidirectional lstm models outperformed multilayer lstm models besides we discuss the findings related to the statistical analysis on simulated datasets for correlation analysis we included features such as external temperature rainfall sunshine population infected cases death country population area and population density of the past three months january february and march in for univariate timeseries forecasting using lstm we used datasets from january to april

ID: gxstlzuk,
Text: genome detective coronavirus typing tool for rapid identification and characterization of novel coronavirus genomes genome detective is a web based user friendly software application to quickly and accurately assemble all known virus genomes from next generation sequencing datasets this application allows the identification of phylogenetic clusters and genotypes from assembled genomes in fasta format since its release in we have produced a number of typing tools for emergent viruses that have caused large outbreaks such as zika and yellow fever virus in brazil here we present the genome detective coronavirus typing tool that can accurately identify novel coronavirus ncov sequences isolated in china and around the world the tool can accept up to sequences per submission and the analysis of a new whole genome sequence will take approximately one minute the tool has been tested and validated with hundreds of whole genomes from ten coronavirus species and correctly classified all of the sars related coronavirus sarsr cov and all of the available public data for ncov the tool also allows tracking of new viral mutations as the outbreak expands globally which may help to accelerate the development of novel diagnostics drugs and vaccines

ID: 6uaj8fb7,
Text: highly ace expression in pancreas may cause pancreas damage after sars cov infection the ongoing outbreak of coronavirus disease covid caused by severe acute respiratory syndrome coronavirus sars cov started in the end of in china has triggered a global public health crisis previous studies have shown that sars cov infects cells by binding angiotensin converting enzyme ace which is the same as sars cov the expression and distribution of ace in the pancreas are unknown at the same time the injury of pancreas after sars cov infection has not been concerned here we collected public datasets bulk rna seq and single cell rna seq to indicate the expression and the distribution of ace in pancreas in both exocrine glands and islets and further clinical data including mild and severe patients with covid demonstrated there existed mild pancreatitis in the severe cases patients showed elevated levels of both amylase and lipase and patients showed imaging alterations only one patient showed elevated levels of both amylase and lipase in mild cases without imaging changes our study revealed the phenomenon and possible cause of mild pancreatic injury in patients with covid this suggests that pancreatitis after sars cov infection should also be paid attention in clinical work

ID: g3sq5j6k,
Text: a transcriptional regulatory atlas of coronavirus infection of human cells identifying transcriptional responses that are most consistently associated with experimental coronavirus cov infection can help illuminate human cellular signaling pathways impacted by cov infection here we distilled over data points from publically archived cov infection transcriptomic datasets into consensus regulatory signatures or consensomes that rank genes based on their transcriptional responsiveness to infection of human cells by mers sars cov and sars cov subtypes we computed overlap between genes with elevated rankings in the cov consensomes against those from transcriptomic and chip seq consensomes for nearly cellular signaling pathway nodes validating the cov infection consensomes we identified robust overlap between their highly ranked genes and high confidence targets of signaling pathway nodes with known roles in cov infection we then developed a series of use cases that illustrate the utility of the cov consensomes for hypothesis generation around mechanistic aspects of the cellular response to cov infection we make the cov infection datasets and their universe of underlying data points freely accessible through the signaling pathways project web knowledgebase at https www signalingpathways org datasets index jsf

ID: ns628u21,
Text: alpha satellite an ai driven system and benchmark datasets for hierarchical community level risk assessment to help combat covid the novel coronavirus and its deadly outbreak have posed grand challenges to human society as of march there have been confirmed cases and reported deaths in the united states and the world health organization who characterized coronavirus disease covid which has infected more than people with more than deaths in at least countries a global pandemic a growing number of areas reporting local sub national community transmission would represent a significant turn for the worse in the battle against the novel coronavirus which points to an urgent need for expanded surveillance so we can better understand the spread of covid and thus better respond with actionable strategies for community mitigation by advancing capabilities of artificial intelligence ai and leveraging the large scale and real time data generated from heterogeneous sources e g disease related data from official public health organizations demographic data mobility data and user geneated data from social media in this work we propose and develop an ai driven system named alpha satellite as an initial offering to provide hierarchical community level risk assessment to assist with the development of strategies for combating the fast evolving covid pandemic more specifically given a specific location either user input or automatic positioning the developed system will automatically provide risk indexes associated with it in a hierarchical manner e g state county city specific location to enable individuals to select appropriate actions for protection while minimizing disruptions to daily life to the extent possible the developed system and the generated benchmark datasets have been made publicly accessible through our website the system description and disclaimer are also available in our website

ID: c9niqu56,
Text: simulating the spread of epidemics in china on the multi layer transportation network beyond the coronavirus in wuhan based on the seir model and the modeling of urban transportation networks a general purpose simulator for the spread of epidemics in chinese cities is built the chinese public transportation system between over prefectural level cities is modeled as a multi layer bi partite network with layers representing different means of transportation airlines railways sail routes and buses and nodes divided into two categories central cities peripheral cities at each city an open system seir model tracks the local spread of the disease with population in and out flow exchanging with the overlying transportation network the model accounts for different transmissivities of the epidemic on different transportation media the transit of inbound flow at cities cross infection on public transportation vehicles due to path overlap and the realistic considerations that the infected population are not entering public transportation and the recovered population are not subject to repeated infections the model could be used to simulate the city level spread in china and potentially other countries of an arbitrary epidemic characterized by its basic reproduction number incubation period infection period and zoonotic force originated from any chinese prefectural level city s during the period before effective government interventions are implemented flowmaps are input into the system to trigger inter city dynamics assuming different flow strength determined from empirical observation within between the bi partite divisions of nodes the model is used to simulate the coronavirus epidemic in wuhan it shows that the framework is robust and reliable and simulated results match public city level datasets to an extraordinary extent

ID: 12l3t9zh,
Text: maskit masking for efficient utilization of incomplete public datasets for training deep learning models a major challenge in training deep learning models is the lack of high quality and complete datasets in the paper we present a masking approach for training deep learning models from a publicly available but incomplete dataset for example city of hamburg germany maintains a list of trees along the roads but this dataset does not contain any information about trees in private homes and parks to train a deep learning model on such a dataset we mask the street trees and aerial images with the road network road network used for creating the mask is downloaded from openstreetmap and it marks the area where the training data is available the mask is passed to the model as one of the inputs and it also coats the output our model learns to successfully predict trees only in the masked region with accuracy

ID: oid5bok9,
Text: masked face recognition dataset and application in order to effectively prevent the spread of covid virus almost everyone wears a mask during coronavirus epidemic this almost makes conventional facial recognition technology ineffective in many cases such as community access control face access control facial attendance facial security checks at train stations etc therefore it is very urgent to improve the recognition performance of the existing face recognition technology on the masked faces most current advanced face recognition approaches are designed based on deep learning which depend on a large number of face samples however at present there are no publicly available masked face recognition datasets to this end this work proposes three types of masked face datasets including masked face detection dataset mfdd real world masked face recognition dataset rmfrd and simulated masked face recognition dataset smfrd among them to the best of our knowledge rmfrd is currently theworld s largest real world masked face dataset these datasets are freely available to industry and academia based on which various applications on masked faces can be developed the multi granularity masked face recognition model we developed achieves accuracy exceeding the results reported by the industry our datasets are available at https github com x zhangyang real world masked face dataset

ID: argclxp1,
Text: genomic analysis and geographic visualization of h n and sars cov emerging infectious diseases and organisms present critical issues of national security public health and economic welfare we still understand little about the zoonotic potential of many viruses to this end we are developing novel database tools to manage comparative genomic datasets these tools add value because they allow us to summarize the direction frequency and order of genomic changes we will perform numerous real world tests with our tools with both avian influenza and coronaviruses

ID: q34w89fa,
Text: oscillations in usa covid incidence and mortality data reflect societal factors the covid pandemic currently in process differs from other infectious disease calamities that have previously plagued humanity in the vast amount of information that is produces each day which includes daily estimates of the disease incidence and mortality data apart from providing actionable information to public health authorities on the trend of the pandemic the daily incidence reflects the process of disease in a susceptible population and thus reflects the pathogenesis of covid the public health response and diagnosis and reporting both daily new cases and daily mortality data in the us exhibit periodic oscillatory patterns by analyzing nyc and la testing data we demonstrate that this oscillation in the number of cases can be strongly explained by the daily variation in testing this seems to rule out alternative hypotheses such as increased infections on certain days of the week as driving this oscillation similarly we show that the apparent oscillation in mortality in the us data is mostly an artifact of reporting which disappears in datasets that record death by episode date such as the nyc and la datasets periodic oscillations in covid incidence and mortality data reflect testing and reporting practices and contingencies thus these contingencies should be considered first prior to suggesting social or biological mechanisms

ID: joacrild,
Text: developing a supervised learning based social media business sentiment index the fast growing digital data generation leads to the emergence of the era of big data which become particularly more valuable because approximately of the collected data in the world comes from social media thus the investigation of online social network services is of paramount importance in this paper we use the sentiment analysis which detects attitudes and emotions toward issues of society posted in social media to understand the actual economic situation to this end two steps are suggested in the first step after training the sentiment classifiers with several big data sources of social media datasets we consider three types of feature sets feature vector sequence vector and a combination of dictionary based feature and sequence vectors then the performance of six classifiers is assessed maxent l c decision tree svm kernel ada boost naïve bayes and maxent in the second step we collect datasets that are relevant to several economic words that the public use to explicitly express their opinions finally we use a vector auto regression analysis to confirm our hypothesis the results show the statistically significant relationship between public sentiment and economic performance that is depression and unemployment lead to kospi also it shows that the extracted keywords from the sentiment analysis such as price year end tax and budget deficit cause the exchange rates

ID: zixj2u7c,
Text: using informatics to guide public health policy during the covid pandemic in the usa background current and future pandemics will require informatics solutions to assess the risks resources and policies to guide better public health decision making methods cross sectional study of all covid cases and deaths in the usa on a population and resource adjusted basis as of april by applying biomedical informatics and data visualization tools to several public and federal government datasets including analysis of the impact of statewide stay at home orders results there were cases and deaths per million residents respectively in the usa with variable distributions throughout divisions regions and states forty two states and washington dc had statewide stay at home orders with the remaining states having population adjusted characteristics in the highest risk quartile conclusions effective national preparedness requires clearly understanding states ability to predict manage and balance public health needs through all stages of a pandemic this will require leveraging data quickly correctly and responsibly into sound public health policies

ID: vpcx2t3w,
Text: the digestive system is a potential route of ncov infection a bioinformatics analysis based on single cell transcriptomes since december a newly identified coronavirus novel coronavirus ncov is causing outbreak of pneumonia in one of largest cities wuhan in hubei province of china and has draw significant public health attention the same as severe acute respiratory syndrome coronavirus sars cov ncov enters into host cells via cell receptor angiotensin converting enzyme ii ace in order to dissect the ace expressing cell composition and proportion and explore a potential route of the ncov infection in digestive system infection datasets with single cell transcriptomes of lung esophagus gastric ileum and colon were analyzed the data showed that ace was not only highly expressed in the lung at cells esophagus upper and stratified epithelial cells but also in absorptive enterocytes from ileum and colon these results indicated along with respiratory systems digestive system is a potential routes for ncov infection in conclusion this study has provided the bioinformatics evidence of the potential route for infection of ncov in digestive system along with respiratory tract and may have significant impact for our healthy policy setting regards to prevention of ncov infection

ID: xn12s005,
Text: unsupervised method based on superpixel segmentation for corpus callosum parcellation in mri scans in this paper we introduce an unsupervised method for the parcellation of the corpus callosum cc from mri images since there are no visible landmarks within the structure that explicit its parcels non geometric cc parcellation is a challenging task especially that almost of proposed methods are geometric or data based in fact in order to subdivide the cc from brain sagittal mri scans we adopt the probabilistic neural network as a clustering technique then we use a cluster validity measure based on the maximum entropy vmep to obtain the optimal number of classes after that we obtain the isolated cc that we parcel automatically using slic simple linear iterative clustering as superpixel segmentation technique the obtained results on two challenging public datasets prove the performance of the proposed method against geometric methods from the state of the art indeed as best as we know it is the first work that investigates the validation of a cc parcellation method on ground truth datasets using many objective metrics

ID: x4clpzte,
Text: covid automatic detection from x ray images utilizing transfer learning with convolutional neural networks in this study a dataset of x ray images from patients with common bacterial pneumonia confirmed covid disease and normal incidents was utilized for the automatic detection of the coronavirus disease the aim of the study is to evaluate the performance of state of the art convolutional neural network architectures proposed over the recent years for medical image classification specifically the procedure called transfer learning was adopted with transfer learning the detection of various abnormalities in small medical image datasets is an achievable target often yielding remarkable results the datasets utilized in this experiment are two firstly a collection of x ray images including images with confirmed covid disease images with confirmed common bacterial pneumonia and images of normal conditions secondly a dataset including images with confirmed covid disease images with confirmed bacterial and viral pneumonia and images of normal conditions the data was collected from the available x ray images on public medical repositories the results suggest that deep learning with x ray imaging may extract significant biomarkers related to the covid disease while the best accuracy sensitivity and specificity obtained is and respectively since by now all diagnostic tests show failure rates such as to raise concerns the probability of incorporating x rays into the diagnosis of the disease could be assessed by the medical community based on the findings while more research to evaluate the x ray approach from different aspects may be conducted

ID: 3iu8qx7n,
Text: using informatics to guide public health policy during the covid pandemic in the usa background current and future pandemics will require informatics solutions to assess the risks resources and policies to guide better public health decision making methods cross sectional study of all covid cases and deaths in the usa on a population and resource adjusted basis as of april by applying biomedical informatics and data visualization tools to several public and federal government datasets including analysis of the impact of statewide stay at home orders results there were cases and deaths per million residents respectively in the usa with variable distributions throughout divisions regions and states forty two states and washington dc had statewide stay at home orders with the remaining states having population adjusted characteristics in the highest risk quartile conclusions effective national preparedness requires clearly understanding states ability to predict manage and balance public health needs through all stages of a pandemic this will require leveraging data quickly correctly and responsibly into sound public health policies

ID: st5idleq,
Text: genome detective coronavirus typing tool for rapid identification and characterization of novel coronavirus genomes summary genome detective is a web based user friendly software application to quickly and accurately assemble all known virus genomes from next generation sequencing datasets this application allows the identification of phylogenetic clusters and genotypes from assembled genomes in fasta format since its release in we have produced a number of typing tools for emergent viruses that have caused large outbreaks such as zika and yellow fever virus in brazil here we present the genome detective coronavirus typing tool that can accurately identify the novel severe acute respiratory syndrome sars related coronavirus sars cov sequences isolated in china and around the world the tool can accept up to sequences per submission and the analysis of a new whole genome sequence will take approximately one minute the tool has been tested and validated with hundreds of whole genomes from ten coronavirus species and correctly classified all of the sars related coronavirus sarsr cov and all of the available public data for sars cov the tool also allows tracking of new viral mutations as the outbreak expands globally which may help to accelerate the development of novel diagnostics drugs and vaccines to stop the covid disease availability https www genomedetective com app typingtool cov supplementary information

ID: dbwfn27p,
Text: single cell rna expression profiling of ace the putative receptor of wuhan ncov in the nasal tissue a novel coronavirus ncov was first identified in wuhan hubei province and then spreads to the other provinces of china who decides to determine a public health emergency of international concern pheic of ncov ncov was reported to share the same receptor angiotensin converting enzyme ace with sars cov here based on the public single cell rna seq datasets we analyzed the ace rna expression profile in the tissues at different locations of the respiratory tract the result indicates that the ace expression appears in nasal epithelial cells we found that the size of this population of ace expressing nasal epithelial cells is comparable with the size of the population of ace expression type ii alveolar cells at in the asian sample reported by yu zhao et al we further detected ncov by polymerase chain reaction pcr from the nasal swab and throat swab of seven suspected cases we found that ncov tends to have a higher concentration in the nasal swab comparing to the throat swab which could attribute to the ace expressing nasal epithelial cells we hope this study could be informative for virus prevention strategy development especially the treatment of nasal mucus

ID: csokkcqq,
Text: evaluating performance of metagenomic characterization algorithms using in silico datasets generated with fastqsim background in silico bacterial viral and human truth datasets were generated to evaluate available metagenomics algorithms sequenced datasets include background organisms creating ambiguity in the true source organism for each read bacterial and viral datasets were created with even and staggered coverage to evaluate organism identification read mapping and gene identification capabilities of available algorithms these truth datasets are provided as a resource for the development and refinement of metagenomic algorithms algorithm performance on these truth datasets can inform decision makers on strengths and weaknesses of available algorithms and how the results may be best leveraged for bacterial and viral organism identification and characterization source organisms were selected to mirror communities described in the human microbiome project as well as the emerging pathogens listed by the national institute of allergy and infectious diseases the six in silico datasets were used to evaluate the performance of six leading metagenomics algorithms metascope kraken lmat metaphlan metacv and metaphyler results algorithms were evaluated on runtime true positive organisms identified to the genus and species levels false positive organisms identified to genus and species level read mapping relative abundance estimation and gene calling no algorithm out performed the others in all categories and the algorithm or algorithms of choice strongly depends on analysis goals metaphlan excels for bacteria and lmat for viruses the algorithms were ranked by overall performance using a normalized weighted sum of the above metrics and metascope emerged as the overall winner followed by kraken and lmat conclusions simulated fastq datasets with well characterized truth data about microbial community composition reveal numerous insights about the relative strengths and weaknesses of the metagenomics algorithms evaluated the simulated datasets are available to download from the sequence read archive srp

ID: kfy7v56x,
Text: analyzing the epidemiological outbreak of covid a visual exploratory data analysis approach there is an obvious concern globally regarding the fact about the emerging coronavirus novel coronavirus ncov as a worldwide public health threat as the outbreak of covid causes by the severe acute respiratory syndrome coronavirus sars cov progresses within china and beyond rapidly available epidemiological data are needed to guide strategies for situational awareness and intervention the recent outbreak of pneumonia in wuhan china caused by the sars cov emphasizes the importance of analyzing the epidemiological data of this novel virus and predicting their risks of infecting people all around the globe in this study we present an effort to compile and analyze epidemiological outbreak information on covid based on the several open datasets on ncov provided by the johns hopkins university world health organization chinese center for disease control and prevention national health commission and dxy an exploratory data analysis with visualizations has been made to understand the number of different cases reported confirmed death and recovered in different provinces of china and outside of china overall at the outset of an outbreak like this it is highly important to readily provide information to begin the evaluation necessary to understand the risks and begin containment activities

ID: 95o2v09d,
Text: google dataset search by the numbers scientists governments and companies increasingly publish datasets on the web google s dataset search extracts dataset metadata expressed using schema org and similar vocabularies from web pages in order to make datasets discoverable since we started the work on dataset search in the number of datasets described in schema org has grown from about k to almost m thus this corpus has become a valuable snapshot of data on the web to the best of our knowledge this corpus is the largest and most diverse of its kind we analyze this corpus and discuss where the datasets originate from what topics they cover which form they take and what people searching for datasets are interested in based on this analysis we identify gaps and possible future work to help make data more discoverable

ID: ef97jzc4,
Text: deep knowledge tracing with transformers in this work we propose a transformer based model to trace students knowledge acquisition we modified the transformer structure to utilize the association between questions and skills and the elapsed time between question steps the use of question skill associations allows the model to learn specific representation for frequently encountered questions while representing rare questions with their underline skill representations the inclusion of elapsed time opens the opportunity to address forgetting our approach outperforms the state of the art methods in the literature by roughly in auc with frequently used public datasets

ID: keaxietu,
Text: understanding economic and health factors impacting the spread of covid disease the rapid spread of the coronavirus disease covid had drastically impacted life all over the world while some economies are actively recovering from this pestilence others are experiencing fast and consistent disease spread compelling governments to impose social distancing measures that have put a halt on routines especially in densely populated areas aiming at bringing more light on key economic and public health factors affecting the disease spread this initial study utilizes a quantitative statistical analysis based on the most recent publicly available covid datasets the study had shown and explained multiple significant relationships between the covid data and other country level statistics we have also identified and statistically profiled four major country level clusters with relation to different aspects of covid development and country level economic and health indicators specifically this study has identified potential covid under reporting traits as well as various economic factors that impact covid diagnosis reporting and treatment based on the country clusters we have also described the four disease development scenarios which are tightly knit to country level economic and public health factors finally we have highlighted the potential limitation of reporting and measuring covid and provided recommendations on further in depth quantitative research

ID: rql9fjug,
Text: analyzing the epidemiological outbreak of covid a visual exploratory data analysis approach there is an obvious concern globally regarding the fact about the emerging coronavirus novel coronavirus ncov as a worldwide public health threat as the outbreak of covid causes by the severe acute respiratory syndrome coronavirus sars cov progresses within china and beyond rapidly available epidemiological data are needed to guide strategies for situational awareness and intervention the recent outbreak of pneumonia in wuhan china caused by the sars cov emphasizes the importance of analyzing the epidemiological data of this novel virus and predicting their risks of infecting people all around the globe in this study we present an effort to compile and analyze epidemiological outbreak information on covid based on the several open datasets on ncov provided by the johns hopkins university world health organization chinese center for disease control and prevention national health commission and dxy an exploratory data analysis with visualizations has been made to understand the number of different cases reported confirmed death and recovered in different provinces of china and outside of china overall at the outset of an outbreak like this it is highly important to readily provide information to begin the evaluation necessary to understand the risks and begin containment activities

ID: zrqp24gb,
Text: major infection events over years how is media coverage influencing online information needs of health care professionals and the public background the last decade witnessed turbulent events in public health emerging infections increase of antimicrobial resistance deliberately released threats and ongoing battles with common illnesses were amplified by the spread of disease through increased international travel the internet has dramatically changed the availability of information about outbreaks however little research has been done in comparing the online behavior of public and professionals around the same events and the effect of media coverage of outbreaks on information needs objective to investigate professional and public online information needs around major infection outbreaks and correlate these with media coverage questions include how do health care professionals online needs for public health and infection control information differ from those of the public does dramatic media coverage of outbreaks contribute to the information needs among the public and how do incidents of diseases and major policy events relate to the information needs of professionals methods we used three longitudinal time based datasets from mid until end of a unique record of professional online behavior on uk infection portals national electronic library of infection and national resource of infection control neli nric equivalent public online information needs google trends and relevant media coverage lexisnexis analysis of neli nric logs identified the highest interest around six major infectious diseases clostridium difficile c difficile methicillin resistant staphylococcus aureus mrsa tuberculosis meningitis norovirus and influenza after pre processing the datasets were analyzed and triangulated with each other results public information needs were more static following the actual disease occurrence less than those of professionals whose needs increase with public health events eg mrsa c difficile and the release of major national policies or important documents media coverage of events resulted in major public interest eg the uk outbreak of c difficile mrsa an exception was norovirus showing a seasonal pattern for both public and professionals which matched the periodic disease occurrence meningitis was a clear example of a disease with heightened media coverage tending to focus on individual and celebrity cases influenza was a major concern during the h n outbreak creating massive public interest in line with the spring and autumn peaks in cases although in autumn there was no corresponding increase in media coverage online resources play an increasing role in fulfilling professionals and public information needs conclusions significant factors related to a surge of professional interest around a disease were typically key publications and major policy changes public interests seem more static and correlate with media influence but to a lesser extent than expected the only exception was norovirus exhibiting online public and professional interest correlating with seasonal occurrences of the disease public health agencies with responsibility for risk communication of public health events in particular during outbreaks and emergencies need to collaborate with media in order to ensure the coverage is high quality and evidence based while professionals information needs remain mainly fulfilled by online open access to key resources
